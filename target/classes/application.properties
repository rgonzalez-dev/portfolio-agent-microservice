# Portfolio Agent Microservice Configuration
spring.application.name=portfolio-agent-microservice

# Server Configuration
server.port=8080
server.servlet.context-path=/api

# Database Configuration (H2)
spring.datasource.url=jdbc:h2:mem:testdb
spring.datasource.driverClassName=org.h2.Driver
spring.datasource.username=sa
spring.datasource.password=

# JPA/Hibernate Configuration
spring.jpa.database-platform=org.hibernate.dialect.H2Dialect
spring.jpa.hibernate.ddl-auto=update
spring.jpa.show-sql=false
spring.jpa.properties.hibernate.format_sql=true

# H2 Console (optional, for development)
spring.h2.console.enabled=true

# Actuator Configuration
management.endpoints.web.exposure.include=health,info,metrics,prometheus
management.endpoint.health.show-details=when-authorized
management.prometheus.metrics.export.enabled=true

# API Documentation (Swagger UI)
springdoc.api-docs.path=/api-docs
springdoc.swagger-ui.path=/swagger-ui.html
springdoc.swagger-ui.enabled=true

# Logging
logging.level.root=INFO
logging.level.rgonzalez.agent=DEBUG

# LLM Provider Configuration
# Available providers: openai, anthropic, local
llm.provider=openai

# OpenAI Configuration
# Set your OpenAI API key here
llm.openai.api-key=${OPENAI_API_KEY:}
llm.openai.model=gpt-4
llm.openai.api-endpoint=https://api.openai.com

# Anthropic Configuration (for future use)
# llm.anthropic.api-key=${ANTHROPIC_API_KEY:}
# llm.anthropic.model=claude-3-opus

# Local LLM Configuration (for Ollama or similar)
# llm.local.endpoint=http://localhost:11434
# llm.local.model=llama2
